"""
å¤šç®—æ³•ç»¼åˆå¯¹æ¯”å¯è§†åŒ–
æ”¯æŒPPOåŸºçº¿ã€GNN-GATã€GNN-GCNä¸‰ç®—æ³•å…¨é¢å¯¹æ¯”
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import argparse
from pathlib import Path
import os
from typing import Dict, List
from scipy import stats

# è®¾ç½®æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("Set2")


def load_training_log(log_file: str) -> pd.DataFrame:
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""
    try:
        df = pd.read_csv(log_file, sep=' ')
        return df
    except Exception as e:
        print(f"åŠ è½½æ—¥å¿—æ–‡ä»¶å¤±è´¥: {log_file}, é”™è¯¯: {e}")
        return None


def plot_comprehensive_comparison(log_files: Dict[str, str], output_dir: str = 'plots/comprehensive/'):
    """
    ç”Ÿæˆä¸‰ç®—æ³•ç»¼åˆå¯¹æ¯”å›¾è¡¨
    
    Args:
        log_files: ç®—æ³•åç§°åˆ°æ—¥å¿—æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
        output_dir: è¾“å‡ºç›®å½•
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. è®­ç»ƒè¿‡ç¨‹å…¨é¢å¯¹æ¯”
    fig = plt.figure(figsize=(20, 12))
    
    # è®¾ç½®å­å›¾å¸ƒå±€ (2è¡Œ3åˆ—)
    axes = [
        plt.subplot(2, 3, 1),  # å¥–åŠ±å¯¹æ¯”
        plt.subplot(2, 3, 2),  # å»¶è¿Ÿå¯¹æ¯”  
        plt.subplot(2, 3, 3),  # æˆåŠŸç‡å¯¹æ¯”
        plt.subplot(2, 3, 4),  # æ”¶æ•›é€Ÿåº¦å¯¹æ¯”
        plt.subplot(2, 3, 5),  # ç¨³å®šæ€§åˆ†æ
        plt.subplot(2, 3, 6),  # ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
    ]
    
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
    algorithm_data = {}
    
    # åŠ è½½æ‰€æœ‰æ•°æ®
    for i, (alg_name, log_file) in enumerate(log_files.items()):
        df = load_training_log(log_file)
        if df is None:
            continue
            
        algorithm_data[alg_name] = df
        color = colors[i % len(colors)]
        
        # 1. å¥–åŠ±æ›²çº¿
        axes[0].plot(df['episode'], df['mean_reward'], 
                    label=alg_name, color=color, linewidth=2.5, alpha=0.8)
        
        # 2. å»¶è¿Ÿæ›²çº¿
        axes[1].plot(df['episode'], df['mean_delay'], 
                    label=alg_name, color=color, linewidth=2.5, alpha=0.8)
        
        # 3. æˆåŠŸç‡æ›²çº¿
        axes[2].plot(df['episode'], df['mean_rate'], 
                    label=alg_name, color=color, linewidth=2.5, alpha=0.8)
        
        # 4. æ”¶æ•›é€Ÿåº¦åˆ†æ (å¥–åŠ±å¯¼æ•°)
        reward_diff = df['mean_reward'].diff().abs()
        smooth_diff = reward_diff.rolling(window=20).mean()
        axes[3].plot(df['episode'][1:], smooth_diff[1:], 
                    label=f'{alg_name} æ”¶æ•›é€Ÿåº¦', color=color, linewidth=2, alpha=0.7)
        
        # 5. ç¨³å®šæ€§åˆ†æ (å¥–åŠ±æ–¹å·®)
        rolling_std = df['mean_reward'].rolling(window=50).std()
        axes[4].plot(df['episode'], rolling_std, 
                    label=f'{alg_name} ç¨³å®šæ€§', color=color, linewidth=2, alpha=0.7)
    
    # è®¾ç½®å­å›¾æ ·å¼
    titles = ['Training Reward Comparison', 'Average Delay Comparison', 
              'Success Rate Comparison', 'Convergence Speed Analysis', 
              'Training Stability Analysis']
    ylabels = ['Average Reward', 'Delay (ms)', 'Success Rate', 
               'Reward Change Rate', 'Reward Std Dev']
    
    for i in range(5):
        axes[i].set_title(titles[i], fontsize=14, fontweight='bold')
        axes[i].set_xlabel('Episode', fontsize=12)
        axes[i].set_ylabel(ylabels[i], fontsize=12)
        axes[i].legend(fontsize=10)
        axes[i].grid(True, alpha=0.3)
    
    # 6. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
    if len(algorithm_data) >= 2:
        plot_radar_chart(algorithm_data, axes[5])
    
    plt.suptitle('Comprehensive Algorithm Comparison: PPO vs GNN-PPO Variants', 
                fontsize=18, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_path = os.path.join(output_dir, 'comprehensive_comparison.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"ç»¼åˆå¯¹æ¯”å›¾ä¿å­˜è‡³: {plot_path}")
    
    plt.show()


def plot_radar_chart(algorithm_data: Dict[str, pd.DataFrame], ax):
    """ç»˜åˆ¶ç»¼åˆæ€§èƒ½é›·è¾¾å›¾"""
    
    # è®¡ç®—å„ç®—æ³•çš„æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡
    metrics = {}
    metric_names = ['Final Reward', 'Low Delay', 'High Success Rate', 
                   'Fast Convergence', 'High Stability']
    
    for alg_name, df in algorithm_data.items():
        final_100 = df.tail(100)
        
        # æ ‡å‡†åŒ–æŒ‡æ ‡ (0-1èŒƒå›´)
        reward_score = (final_100['mean_reward'].mean() - df['mean_reward'].min()) / \
                      (df['mean_reward'].max() - df['mean_reward'].min())
        
        delay_score = 1 - (final_100['mean_delay'].mean() - df['mean_delay'].min()) / \
                     (df['mean_delay'].max() - df['mean_delay'].min())  # å»¶è¿Ÿè¶Šä½è¶Šå¥½
        
        rate_score = (final_100['mean_rate'].mean() - df['mean_rate'].min()) / \
                    (df['mean_rate'].max() - df['mean_rate'].min())
        
        # æ”¶æ•›é€Ÿåº¦ (å‰50%è¾¾åˆ°æœ€ç»ˆæ€§èƒ½90%çš„é€Ÿåº¦)
        final_reward = final_100['mean_reward'].mean()
        target_reward = final_reward * 0.9
        convergence_episode = len(df[df['mean_reward'] < target_reward])
        convergence_score = 1 - convergence_episode / len(df)
        
        # ç¨³å®šæ€§ (æœ€å100ä¸ªepisodeçš„æ–¹å·®ï¼Œè¶Šå°è¶Šå¥½)
        stability_score = 1 - (final_100['mean_reward'].std() / df['mean_reward'].std())
        
        metrics[alg_name] = [reward_score, delay_score, rate_score, 
                           convergence_score, stability_score]
    
    # ç»˜åˆ¶é›·è¾¾å›¾
    angles = np.linspace(0, 2*np.pi, len(metric_names), endpoint=False).tolist()
    angles += angles[:1]  # é—­åˆå›¾å½¢
    
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
    
    for i, (alg_name, values) in enumerate(metrics.items()):
        values += values[:1]  # é—­åˆæ•°æ®
        color = colors[i % len(colors)]
        
        ax.plot(angles, values, 'o-', linewidth=2, label=alg_name, color=color)
        ax.fill(angles, values, alpha=0.15, color=color)
    
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(metric_names, fontsize=10)
    ax.set_ylim(0, 1)
    ax.set_title('Comprehensive Performance Radar', fontsize=14, fontweight='bold')
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
    ax.grid(True)


def plot_statistical_comparison(log_files: Dict[str, str], output_dir: str = 'plots/comprehensive/'):
    """
    ç»Ÿè®¡æ˜¾è‘—æ€§å¯¹æ¯”åˆ†æ
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    algorithm_data = {}
    for alg_name, log_file in log_files.items():
        df = load_training_log(log_file)
        if df is not None:
            algorithm_data[alg_name] = df.tail(100)  # æœ€å100ä¸ªepisodes
    
    if len(algorithm_data) < 2:
        print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡å¯¹æ¯”")
        return
    
    # åˆ›å»ºå¯¹æ¯”çŸ©é˜µå›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Statistical Significance Analysis', fontsize=16, fontweight='bold')
    
    algorithms = list(algorithm_data.keys())
    metrics = ['mean_reward', 'mean_delay', 'mean_rate']
    metric_names = ['Average Reward', 'Average Delay', 'Success Rate']
    
    # 1. ç®±çº¿å›¾å¯¹æ¯”
    for i, (metric, name) in enumerate(zip(metrics, metric_names)):
        ax = axes[i//2, i%2] if i < 3 else axes[1, 1]
        
        data_for_box = []
        labels_for_box = []
        
        for alg_name in algorithms:
            if metric in algorithm_data[alg_name].columns:
                data_for_box.append(algorithm_data[alg_name][metric].values)
                labels_for_box.append(alg_name)
        
        if data_for_box:
            bp = ax.boxplot(data_for_box, labels=labels_for_box, patch_artist=True)
            
            # è®¾ç½®é¢œè‰²
            colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            
            ax.set_title(f'{name} Distribution', fontweight='bold')
            ax.set_ylabel(name)
            ax.grid(True, alpha=0.3)
    
    # 4. ç»Ÿè®¡æ˜¾è‘—æ€§çŸ©é˜µ
    if len(algorithms) >= 2:
        ax = axes[1, 1]
        
        # åˆ›å»ºpå€¼çŸ©é˜µ
        n_algs = len(algorithms)
        p_matrix = np.ones((n_algs, n_algs))
        
        for i in range(n_algs):
            for j in range(i+1, n_algs):
                alg1, alg2 = algorithms[i], algorithms[j]
                
                # å¯¹å¥–åŠ±è¿›è¡Œtæ£€éªŒ
                data1 = algorithm_data[alg1]['mean_reward'].values
                data2 = algorithm_data[alg2]['mean_reward'].values
                
                _, p_value = stats.ttest_ind(data1, data2)
                p_matrix[i, j] = p_value
                p_matrix[j, i] = p_value
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        im = ax.imshow(p_matrix, cmap='RdYlGn_r', vmin=0, vmax=0.1)
        
        # æ·»åŠ æ–‡æœ¬æ³¨é‡Š
        for i in range(n_algs):
            for j in range(n_algs):
                text = ax.text(j, i, f'{p_matrix[i, j]:.4f}', 
                             ha='center', va='center', fontweight='bold',
                             color='white' if p_matrix[i, j] < 0.05 else 'black')
        
        ax.set_xticks(range(n_algs))
        ax.set_yticks(range(n_algs))
        ax.set_xticklabels(algorithms, rotation=45)
        ax.set_yticklabels(algorithms)
        ax.set_title('Statistical Significance (p-values)', fontweight='bold')
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax, shrink=0.8)
        cbar.set_label('p-value', rotation=270, labelpad=15)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_path = os.path.join(output_dir, 'statistical_analysis.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"ç»Ÿè®¡åˆ†æå›¾ä¿å­˜è‡³: {plot_path}")
    
    plt.show()


def create_comprehensive_report(log_files: Dict[str, str], output_dir: str = 'plots/comprehensive/'):
    """
    åˆ›å»ºç»¼åˆå®éªŒæŠ¥å‘Š
    """
    os.makedirs(output_dir, exist_ok=True)
    
    print("\\n" + "="*100)
    print("ğŸ“Š GNN-PPO å¤šç®—æ³•ç»¼åˆå¯¹æ¯”å®éªŒæŠ¥å‘Š")
    print("="*100)
    
    # æ”¶é›†æ•°æ®
    algorithm_results = {}
    for alg_name, log_file in log_files.items():
        df = load_training_log(log_file)
        if df is not None:
            final_100 = df.tail(100)
            
            algorithm_results[alg_name] = {
                'æœ€ç»ˆå¹³å‡å¥–åŠ±': final_100['mean_reward'].mean(),
                'å¥–åŠ±æ ‡å‡†å·®': final_100['mean_reward'].std(),
                'æœ€ç»ˆå¹³å‡å»¶è¿Ÿ': final_100['mean_delay'].mean(),
                'å»¶è¿Ÿæ ‡å‡†å·®': final_100['mean_delay'].std(),
                'æœ€ç»ˆæˆåŠŸç‡': final_100['mean_rate'].mean(),
                'æˆåŠŸç‡æ ‡å‡†å·®': final_100['mean_rate'].std(),
                'æœ€ä½³å¥–åŠ±': df['mean_reward'].max(),
                'æœ€ä½å»¶è¿Ÿ': df['mean_delay'].min(),
                'æœ€é«˜æˆåŠŸç‡': df['mean_rate'].max(),
                'æ•°æ®ç‚¹æ•°': len(df)
            }
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    if len(algorithm_results) >= 2:
        print(f"\\n{'ç®—æ³•':<20} {'æœ€ç»ˆå¥–åŠ±':<15} {'æœ€ç»ˆå»¶è¿Ÿ':<15} {'æˆåŠŸç‡':<15} {'å¥–åŠ±ç¨³å®šæ€§':<15}")
        print("-" * 80)
        
        for alg_name, results in algorithm_results.items():
            print(f"{alg_name:<20} "
                  f"{results['æœ€ç»ˆå¹³å‡å¥–åŠ±']:<15.3f} "
                  f"{results['æœ€ç»ˆå¹³å‡å»¶è¿Ÿ']:<15.2f} "
                  f"{results['æœ€ç»ˆæˆåŠŸç‡']:<15.3f} "
                  f"{results['å¥–åŠ±æ ‡å‡†å·®']:<15.4f}")
        
        # è®¡ç®—ç›¸å¯¹æ”¹è¿›
        if len(algorithm_results) >= 2:
            algorithms = list(algorithm_results.keys())
            baseline = None
            gnn_algorithms = []
            
            for alg_name in algorithms:
                if 'baseline' in alg_name.lower() or 'ppo' in alg_name.lower():
                    baseline = algorithm_results[alg_name]
                    baseline_name = alg_name
                elif 'gnn' in alg_name.lower():
                    gnn_algorithms.append((alg_name, algorithm_results[alg_name]))
            
            if baseline and gnn_algorithms:
                print(f"\\nğŸ¯ ç›¸å¯¹äº{baseline_name}çš„æ”¹è¿›:")
                print("-" * 50)
                
                for gnn_name, gnn_results in gnn_algorithms:
                    reward_improvement = (gnn_results['æœ€ç»ˆå¹³å‡å¥–åŠ±'] - baseline['æœ€ç»ˆå¹³å‡å¥–åŠ±']) / abs(baseline['æœ€ç»ˆå¹³å‡å¥–åŠ±']) * 100
                    delay_improvement = (baseline['æœ€ç»ˆå¹³å‡å»¶è¿Ÿ'] - gnn_results['æœ€ç»ˆå¹³å‡å»¶è¿Ÿ']) / baseline['æœ€ç»ˆå¹³å‡å»¶è¿Ÿ'] * 100
                    rate_improvement = (gnn_results['æœ€ç»ˆæˆåŠŸç‡'] - baseline['æœ€ç»ˆæˆåŠŸç‡']) / baseline['æœ€ç»ˆæˆåŠŸç‡'] * 100
                    
                    print(f"{gnn_name}:")
                    print(f"  ğŸ“ˆ å¥–åŠ±æ”¹è¿›: {reward_improvement:+.2f}%")
                    print(f"  âš¡ å»¶è¿Ÿé™ä½: {delay_improvement:+.2f}%")
                    print(f"  âœ… æˆåŠŸç‡æå‡: {rate_improvement:+.2f}%")
                    print()
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_path = os.path.join(output_dir, 'comprehensive_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("GNN-PPO å¤šç®—æ³•ç»¼åˆå¯¹æ¯”å®éªŒæŠ¥å‘Š\\n")
        f.write("="*50 + "\\n\\n")
        
        for alg_name, results in algorithm_results.items():
            f.write(f"ç®—æ³•: {alg_name}\\n")
            for key, value in results.items():
                f.write(f"  {key}: {value:.4f}\\n")
            f.write("\\n")
    
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šä¿å­˜è‡³: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¤šç®—æ³•ç»¼åˆå¯¹æ¯”å¯è§†åŒ–')
    parser.add_argument('--logs', type=str, nargs='+', required=True,
                       help='ç®—æ³•åç§°:æ—¥å¿—è·¯å¾„ æ ¼å¼ï¼Œä¾‹å¦‚ PPO:log1.log GNN_GAT:log2.log')
    parser.add_argument('--output_dir', type=str, default='plots/comprehensive/',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--plot_type', type=str, default='all',
                       choices=['comparison', 'statistical', 'report', 'all'],
                       help='ç»˜åˆ¶ç±»å‹')
    
    args = parser.parse_args()
    
    # è§£ææ—¥å¿—æ–‡ä»¶å‚æ•°
    log_files = {}
    for log_arg in args.logs:
        if ':' in log_arg:
            alg_name, log_path = log_arg.split(':', 1)
            if os.path.exists(log_path):
                log_files[alg_name] = log_path
            else:
                print(f"âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_path}")
        else:
            print(f"âš ï¸  æ—¥å¿—å‚æ•°æ ¼å¼é”™è¯¯: {log_arg}")
    
    if not log_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ—¥å¿—æ–‡ä»¶")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(log_files)} ä¸ªç®—æ³•æ—¥å¿—ï¼Œå¼€å§‹åˆ†æ...")
    for alg_name, log_path in log_files.items():
        print(f"  - {alg_name}: {log_path}")
    
    # ç”Ÿæˆåˆ†æå›¾è¡¨
    if args.plot_type in ['comparison', 'all']:
        plot_comprehensive_comparison(log_files, args.output_dir)
    
    if args.plot_type in ['statistical', 'all']:
        plot_statistical_comparison(log_files, args.output_dir)
    
    if args.plot_type in ['report', 'all']:
        create_comprehensive_report(log_files, args.output_dir)
    
    print("\\nâœ… å¤šç®—æ³•å¯¹æ¯”åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()